# This is a basic workflow to help you get started with Actions

name: Scrape

# Controls when the workflow will run
on:
  schedule:
    - cron: "0 8 * * *" # 8 a.m. every day UTC
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  scrape:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
      - name: Install dependencies
        run: |-
            python -m pip install --upgrade pip
            pip install pandas
            pip install requests
      - uses: jannekem/run-python-script-action@v1
        with:
          script: |
            import pandas as pd
            import pandas as pd

            projects = pd.DataFrame()
            boroughs = ['Manhattan','Bronx','Brooklyn','Queens','Staten%20Island']

            for borough in boroughs: 
              url = 'https://zap-api-production.herokuapp.com/projects.csv?page=1&block=&boroughs%5B0%5D='+borough+'&dcp_publicstatus%5B0%5D=In%20Public%20Review&dcp_publicstatus%5B1%5D=Noticed'
              projects = projects.append(pd.read_csv(url))

            projects = projects.reset_index(drop=True)
            projects.to_csv("data")
              
        # commit and push the saved data    
      - name: Add and commit
        id: add_commit
        uses: EndBug/add-and-commit@v8
        with:
          committer_name: Automated
          committer_email: actions@users.noreply.github.com
          message: "Latest data"
      - name: Push	
        run: git push
        

  
